## Essay Summary

This essay was written for the course  

<p align="center">
<strong>Technology, Economy, Society (ED0038)</strong>
</p>

This essay presents a philosophical review of  
[**Artificial Intelligence, Responsibility Attribution, and a Relational Justification of Explainability**]([https://link.springer.com/article/10.1007/s11948-019-00146-8](https://link.springer.com/article/10.1007/s11948-019-00146-8))  
by Mark Coeckelbergh (2020).

The review examines the philosophical foundations of responsibility in AI-driven systems, 
focusing on how responsibility can be attributed in complex socio-technical environments. 
It discusses ethical issues related to explainability, transparency, and accountability, 
drawing on Aristotelian concepts of moral responsibility.

In particular, the review highlights two key conditions for responsibility discussed in the article: 
the **control condition**, which concerns whether an agent has sufficient control over actions and decisions, 
and the **epistemic condition**, which concerns whether an agent has adequate knowledge and understanding of those actions and their consequences. 
The complexity and opacity of AI systems challenge both conditions, making responsibility attribution more difficult.
